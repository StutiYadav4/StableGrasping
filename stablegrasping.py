# -*- coding: utf-8 -*-
"""StableGrasping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j2yqNVuoDNXiPDHVEnWNd039qnUJKbW_

Imports
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,roc_auc_score, roc_curve, precision_recall_curve, auc, accuracy_score, confusion_matrix, classification_report
import tensorflow as tf
from sklearn.svm import SVC
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier

device = torch.cuda.is_available()
print(device)

"""Data Pre-Processing"""

url = "/content/shadow_robot_dataset.csv"
df = pd.read_csv(url)

print(df.columns)

df=df.drop(columns=['experiment_number',' measurement_number'])

#Data Standardization
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)
df_scaled = pd.DataFrame(df_scaled, columns=df.columns)
df_scaled.head()

df.shape

X=df_scaled.drop(columns=[' robustness'])
y=df_scaled[' robustness']

"""Exploratory Data Analysis"""

df.describe()

df.info()

df.hist(figsize=(15, 12))
plt.show()

corr_matrix = df.corr()
plt.figure(figsize=(15, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True,
            annot_kws={"size": 8},
            cbar_kws={"shrink": .8})

plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(rotation=0, fontsize=10)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, palette="pastel")
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.ylim(-100, 250)
plt.tight_layout()
plt.show()

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)

"""Handling Outliers/ Outlier Detection"""

data_train = pd.concat([y_train,X_train], axis=1)

plt.figure(figsize=(10, 6))
sns.boxplot(data=data_train, palette="pastel")
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.ylim(-100, 250)
plt.tight_layout()
plt.show()

"""a) Removing Outliers

"""

# Documentation
# filter_outliers function -

# Input:

# df: A pandas DataFrame containing numerical data, including features and a target column (e.g., robustness).
# k: An optional parameter (default k=3) to define the number of standard deviations used to identify outliers.
# Output:

# filtered_df: A pandas DataFrame where rows containing outliers in any column (defined as values outside the range mean ± k * std_dev) are removed.

def filter_outliers(df, k=3):
    filtered_df = df.copy()
    for column in df.columns:
        mean = df[column].mean()
        std_dev = df[column].std()
        upper_bound = mean + k * std_dev
        lower_bound = mean - k * std_dev

        filtered_df = filtered_df[(filtered_df[column] >= lower_bound) &
                                   (filtered_df[column] <= upper_bound)]
    return filtered_df

filtered_data = filter_outliers(data_train)
X_filtered = filtered_data.drop(columns=[' robustness'])
y_filtered = filtered_data[' robustness']

model = DecisionTreeRegressor(random_state=42)
model.fit(X_filtered, y_filtered)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.4f}')
print(f'R² Score: {r2:.4f}')

data_train.shape

filtered_data.shape

"""b) Replacing the Outliers with Mean"""

# Documentation
# replace_outliers function -

# Input:

# df: A pandas DataFrame containing the data with numerical columns.
# k: An optional parameter (default k=3) to define the number of standard deviations for identifying outliers.
# Output:

# replaced_df: A pandas DataFrame where outliers in each column are replaced by the column's mean (or median if you choose the other variant). Outliers are defined as values outside the range mean ± k * std_dev.

def replace_outliers(df, k=3):
    replaced_df = df.copy()
    for column in df.columns:
        mean = df[column].mean()
        std_dev = df[column].std()
        upper_bound = mean + k * std_dev
        lower_bound = mean - k * std_dev

        replaced_df[column] = replaced_df[column].where(
            (replaced_df[column] >= lower_bound) & (replaced_df[column] <= upper_bound),
            mean
        )
    return replaced_df
replaced_data = replace_outliers(data_train)

X_replaced = replaced_data.drop(columns=[' robustness'])
y_replaced = replaced_data[' robustness']

model = DecisionTreeRegressor(random_state=42)
model.fit(X_replaced, y_replaced)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.4f}')
print(f'R² Score: {r2:.4f}')

# By removing the outliers, the model is performing better than by replacing them with the mean.
# In both cases, a desicion tree regressor model is used for testing the accuracy.

# Overall model is performing better without handling outliers

"""Dimension Reduction / Feature selection"""

data_copy = df.copy()

"""a) From correlation matrix"""

correlated_features = {}
threshold = 0.8

for i in range(len(corr_matrix.columns)):
    for j in range(i):
        if abs(corr_matrix.iloc[i, j]) > threshold:
            colname = corr_matrix.columns[i]
            other_colname = corr_matrix.columns[j]
            if colname not in correlated_features:
                correlated_features[colname] = []
            correlated_features[colname].append(other_colname)
print("Correlated features:", correlated_features)
to_drop = set()
for feature, others in correlated_features.items():
    target_corrs = {feature: abs(data_copy[feature].corr(data_copy[' robustness']))}
    for other in others:
        target_corrs[other] = abs(data_copy[other].corr(data_copy[' robustness']))
    print("Target correlations:", target_corrs)
    feature_to_keep = max(target_corrs, key=target_corrs.get)
    features_to_drop = [f for f in target_corrs if f != feature_to_keep]
    to_drop.update(features_to_drop)
data_reduced = data_copy.drop(columns=to_drop)

print("Features to drop:", to_drop)
print("Reduced dataset shape:", data_reduced.shape)

X_reduced=data_reduced.drop(columns=[' robustness'])
y_reduced=data_reduced[' robustness']

from sklearn.model_selection import train_test_split
X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(X_reduced, y_reduced, test_size=0.3, random_state=42)

imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train_reduced)
X_test_imputed = imputer.transform(X_test_reduced)

model = LinearRegression()
model.fit(X_train_imputed, y_train_reduced)
y_pred_replaced = model.predict(X_test_imputed)
mse_replaced = mean_squared_error(y_test_reduced, y_pred_replaced)
r2_replaced = r2_score(y_test_reduced, y_pred_replaced)
print("Linear Regression:")
print(f'Mean Squared Error (Reduced): {mse_replaced:.4f}')
print(f'R² Score (Reduced): {r2_replaced:.4f}')

model = DecisionTreeRegressor(random_state=42)
model.fit(X_train_imputed, y_train_reduced)
y_pred = model.predict(X_test_imputed)
mse = mean_squared_error(y_test_reduced, y_pred)
r2 = r2_score(y_test_reduced, y_pred)
print("Decision Tree:")
print(f'Mean Squared Error: {mse:.4f}')
print(f'R² Score: {r2:.4f}')

"""b) By PCA"""

n=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]
for i in n:
  pca = PCA(n_components=i)
  pca.fit(X_train_imputed)
  X_train_ni = pca.transform(X_train_imputed)
  X_test_ni = pca.transform(X_test_imputed)
  classifier_pca = DecisionTreeRegressor(random_state=42)
  classifier_pca.fit(X_train_ni, y_train)
  y_pred_ni = classifier_pca.predict(X_test_ni)

  print("Accuracy for n =",i)
  mse = mean_squared_error(y_test, y_pred_ni)
  r2 = r2_score(y_test, y_pred_ni)
  print(f"Mean Squared Error: {mse:.4f}")
  print(f"R² Score: {r2:.4f}")

# Accuracy of the model by correlation matrix is better than that obtained by PCA.

"""Model Selection and Evaluation

1. Regression

a) Linear Regression
"""

model = LinearRegression()
model.fit(X_train_imputed, y_train_reduced)
y_pred_replaced = model.predict(X_test_imputed)
mse_replaced = mean_squared_error(y_test_reduced, y_pred_replaced)
r2_replaced = r2_score(y_test_reduced, y_pred_replaced)
print("linear regresion ")
print(f'Mean Squared Error (Reduced): {mse_replaced:.4f}')
print(f'R² Score (Reduced): {r2_replaced:.4f}')

"""b) Decision Tree Regressor"""

model = DecisionTreeRegressor(random_state=42)
model.fit(X_train_imputed, y_train_reduced)
y_pred = model.predict(X_test_imputed)
mse = mean_squared_error(y_test_reduced, y_pred)
r2 = r2_score(y_test_reduced, y_pred)
print("decisiontree")
print(f'Mean Squared Error: {mse:.4f}')
print(f'R² Score: {r2:.4f}')

"""2. Deep Learning

a) Artificial Neural Network
"""

X_train_tensor = torch.FloatTensor(X_train_imputed)
y_train_tensor = torch.FloatTensor(y_train_reduced.to_numpy()).view(-1, 1)
X_test_tensor = torch.FloatTensor(X_test_imputed)
y_test_tensor = torch.FloatTensor(y_test_reduced.to_numpy()).view(-1, 1)

# Documentation
#ANNModel class:

# Input:
# The model takes a tensor of shape (batch_size, input_size) as input, where:

# batch_size is the number of samples in each batch.
# input_size corresponds to the number of features in the input data (e.g., X_train_reduced.shape[1]).
# Output:
# The model produces a tensor of shape (batch_size, 1) as output, which represents the predicted values for each input sample. In this case, it predicts continuous values since the model uses Mean Squared Error (MSE) loss for regression tasks.

# For each input sample, the output is a single predicted value (continuous) representing the target variable.

class ANNModel(nn.Module):
    def __init__(self, input_size):
        super(ANNModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.bn1 = nn.BatchNorm1d(128)
        self.fc2 = nn.Linear(128, 64)
        self.bn2 = nn.BatchNorm1d(64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, 1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.bn1(self.fc1(x)))
        x = self.relu(self.bn2(self.fc2(x)))
        x = self.fc3(x)
        x = self.fc4(x)
        return x

input_size = X_train_imputed.shape[1]
model = ANNModel(input_size)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
num_epochs = 1000
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()
    outputs = model(X_train_tensor)
    loss = criterion(outputs, y_train_tensor)
    loss.backward()
    optimizer.step()
    if (epoch + 1) % 100 == 0:
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')

model.eval()
with torch.no_grad():
    y_pred_tensor = model(X_test_tensor)
y_pred = y_pred_tensor.numpy()
mse = mean_squared_error(y_test_tensor, y_pred)
r2 = r2_score(y_test_tensor, y_pred)

print(f'Mean Squared Error: {mse:.4f}')
print(f'R² Score: {r2:.4f}')

"""3. Classification"""

column_name = ' robustness'
min_value = data_reduced[column_name].min()
max_value = data_reduced[column_name].max()
range_value = max_value - min_value
print(min_value)
print(max_value)
q1 = data_reduced[column_name].quantile(0.30)
print(q1)
first_25_percent = data_reduced[data_reduced[column_name] <= q1]
print(data_reduced.shape)
print(first_25_percent.shape)

"""Value > 17.2922569038 : Stable
Value < 17.2922569038 : Unstable
"""

y_classification_train = y_train_reduced.apply(lambda x: 'Unstable' if x > threshold else 'Stable')
y_classification_test = y_test_reduced.apply(lambda x: 'Unstable' if x > threshold else 'Stable')

print(y_classification_train)

"""a) Logistic Regression"""

model = LogisticRegression(max_iter=200)
model.fit(X_train_imputed, y_classification_train)
y_pred = model.predict(X_test_imputed)
accuracy = accuracy_score(y_classification_test, y_pred)

conf_matrix = confusion_matrix(y_classification_test, y_pred)
class_report = classification_report(y_classification_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(class_report)

"""b) Naive Bayes Classifier"""

model = GaussianNB()
model.fit(X_train_imputed, y_classification_train)
y_pred = model.predict(X_test_imputed)
accuracy = accuracy_score(y_classification_test, y_pred)
conf_matrix = confusion_matrix(y_classification_test, y_pred)
class_report = classification_report(y_classification_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(class_report)

"""c) Random Forest Classifier"""

model = RandomForestClassifier(n_estimators=10, random_state=42)
model.fit(X_train_imputed, y_classification_train)
y_pred = model.predict(X_test_imputed)
accuracy = accuracy_score(y_classification_test, y_pred)
conf_matrix = confusion_matrix(y_classification_test, y_pred)
class_report = classification_report(y_classification_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(class_report)

"""d) Support Vector Machines"""

model = SVC(kernel='rbf', random_state=42)
model.fit(X_train_imputed, y_classification_train)
y_pred = model.predict(X_test_imputed)
accuracy = accuracy_score(y_classification_test, y_pred)
conf_matrix = confusion_matrix(y_classification_test, y_pred)
class_report = classification_report(y_classification_test, y_pred)
print(f'Accuracy: {accuracy:.4f}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(class_report)